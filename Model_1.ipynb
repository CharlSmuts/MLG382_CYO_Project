{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a38bce1",
   "metadata": {},
   "source": [
    "Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b4f7dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Import Modules for Neural Network\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34749d31",
   "metadata": {},
   "source": [
    "Display Data and info of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a359e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>14.858000</td>\n",
       "      <td>14.883333</td>\n",
       "      <td>14.217333</td>\n",
       "      <td>14.620667</td>\n",
       "      <td>71466000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>14.303333</td>\n",
       "      <td>14.433333</td>\n",
       "      <td>13.810667</td>\n",
       "      <td>14.006000</td>\n",
       "      <td>80527500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>14.004000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>13.614000</td>\n",
       "      <td>14.085333</td>\n",
       "      <td>93928500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>14.223333</td>\n",
       "      <td>14.318667</td>\n",
       "      <td>13.985333</td>\n",
       "      <td>14.063333</td>\n",
       "      <td>44526000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>14.187333</td>\n",
       "      <td>14.253333</td>\n",
       "      <td>14.000667</td>\n",
       "      <td>14.041333</td>\n",
       "      <td>51637500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date       Open       High        Low      Close  \\\n",
       "0           0  2015-01-02  14.858000  14.883333  14.217333  14.620667   \n",
       "1           1  2015-01-05  14.303333  14.433333  13.810667  14.006000   \n",
       "2           2  2015-01-06  14.004000  14.280000  13.614000  14.085333   \n",
       "3           3  2015-01-07  14.223333  14.318667  13.985333  14.063333   \n",
       "4           4  2015-01-08  14.187333  14.253333  14.000667  14.041333   \n",
       "\n",
       "     Volume  \n",
       "0  71466000  \n",
       "1  80527500  \n",
       "2  93928500  \n",
       "3  44526000  \n",
       "4  51637500  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Data Set 1\n",
    "df_1 = pd.read_csv(\"Data/005930.KS_weekly.csv\")\n",
    "\n",
    "#Display df1\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0530349b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>38700.0</td>\n",
       "      <td>39400.0</td>\n",
       "      <td>36850.0</td>\n",
       "      <td>38750.0</td>\n",
       "      <td>33061.843750</td>\n",
       "      <td>47177112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>40700.0</td>\n",
       "      <td>37950.0</td>\n",
       "      <td>40050.0</td>\n",
       "      <td>34171.023438</td>\n",
       "      <td>68587020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>40050.0</td>\n",
       "      <td>42750.0</td>\n",
       "      <td>39850.0</td>\n",
       "      <td>42750.0</td>\n",
       "      <td>36474.683594</td>\n",
       "      <td>54106211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>42750.0</td>\n",
       "      <td>45500.0</td>\n",
       "      <td>41350.0</td>\n",
       "      <td>45050.0</td>\n",
       "      <td>38437.058594</td>\n",
       "      <td>76571367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-28</td>\n",
       "      <td>45050.0</td>\n",
       "      <td>47050.0</td>\n",
       "      <td>44350.0</td>\n",
       "      <td>46350.0</td>\n",
       "      <td>39546.238281</td>\n",
       "      <td>69174596.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Open     High      Low    Close     Adj Close      Volume\n",
       "0  2018-12-31  38700.0  39400.0  36850.0  38750.0  33061.843750  47177112.0\n",
       "1  2019-01-07  38000.0  40700.0  37950.0  40050.0  34171.023438  68587020.0\n",
       "2  2019-01-14  40050.0  42750.0  39850.0  42750.0  36474.683594  54106211.0\n",
       "3  2019-01-21  42750.0  45500.0  41350.0  45050.0  38437.058594  76571367.0\n",
       "4  2019-01-28  45050.0  47050.0  44350.0  46350.0  39546.238281  69174596.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Data Set 1\n",
    "df_2 = pd.read_csv(\"Data/005930.KS_weekly.csv\")\n",
    "\n",
    "#Display df1\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3efeb7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>38700.0</td>\n",
       "      <td>47050.0</td>\n",
       "      <td>36850.0</td>\n",
       "      <td>46150.0</td>\n",
       "      <td>39375.601562</td>\n",
       "      <td>301783852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>46650.0</td>\n",
       "      <td>47550.0</td>\n",
       "      <td>44250.0</td>\n",
       "      <td>45100.0</td>\n",
       "      <td>38479.726562</td>\n",
       "      <td>194923203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-28</td>\n",
       "      <td>45100.0</td>\n",
       "      <td>47000.0</td>\n",
       "      <td>43100.0</td>\n",
       "      <td>44650.0</td>\n",
       "      <td>38095.785156</td>\n",
       "      <td>223260605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>45200.0</td>\n",
       "      <td>47600.0</td>\n",
       "      <td>43800.0</td>\n",
       "      <td>45850.0</td>\n",
       "      <td>39427.402344</td>\n",
       "      <td>209113436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>45850.0</td>\n",
       "      <td>46150.0</td>\n",
       "      <td>40850.0</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>36546.667969</td>\n",
       "      <td>271585071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Open     High      Low    Close     Adj Close     Volume\n",
       "0  2018-12-31  38700.0  47050.0  36850.0  46150.0  39375.601562  301783852\n",
       "1  2019-01-31  46650.0  47550.0  44250.0  45100.0  38479.726562  194923203\n",
       "2  2019-02-28  45100.0  47000.0  43100.0  44650.0  38095.785156  223260605\n",
       "3  2019-03-31  45200.0  47600.0  43800.0  45850.0  39427.402344  209113436\n",
       "4  2019-04-30  45850.0  46150.0  40850.0  42500.0  36546.667969  271585071"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Data Set 1\n",
    "df_3 = pd.read_csv(\"Data/005930.KS_monthly.csv\")\n",
    "\n",
    "#Display df1\n",
    "df_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c24901",
   "metadata": {},
   "source": [
    "Display Data in graph per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dde5c4a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Adj Close'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ruanl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Adj Close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 3. Plotting the Price Data (using Adj Close as the primary example)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))  \u001b[38;5;66;03m# Adjust figure size for better readability\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mdf_1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAdj Close\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdj Close Price\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdjusted Close Price Over Time\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ruanl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\ruanl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Adj Close'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 3. Plotting the Price Data (using Adj Close as the primary example)\n",
    "plt.figure(figsize=(12, 6))  # Adjust figure size for better readability\n",
    "plt.plot(df_1['Adj Close'], label='Adj Close Price', color='blue')\n",
    "plt.title('Adjusted Close Price Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Adj Close Price')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 4. Plotting Volume\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_1['Volume'], label='Volume', color='green')\n",
    "plt.title('Trading Volume Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volume')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 5.  Plotting Multiple Price Components (Optional - for comparison)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_1['Open'], label='Open', alpha=0.5)\n",
    "plt.plot(df_1['High'], label='High', alpha=0.5)\n",
    "plt.plot(df_1['Low'], label='Low', alpha=0.5)\n",
    "plt.plot(df_1['Close'], label='Close', alpha=1)  # Emphasize Close\n",
    "plt.title('Open, High, Low, and Close Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d98cea",
   "metadata": {},
   "source": [
    "Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71c85307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Features and Target\n",
    "features = ['Open', 'High', 'Low', 'Volume']\n",
    "target = 'Adj Close'\n",
    "\n",
    "#Copy Df_1\n",
    "df_1_copy = df_1[features + [target]].copy()\n",
    "\n",
    "#Scale the Data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df_1_copy)\n",
    "\n",
    "#Separate features and target\n",
    "X = scaled_data[:, :-1]\n",
    "y = scaled_data[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c2b041",
   "metadata": {},
   "source": [
    "Prepare Secuences for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa6b1877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Number of Days to use for prediction\n",
    "seq_length = 50\n",
    "xs = []\n",
    "ys = []\n",
    "for i in range(len(X) - seq_length):\n",
    "    xs.append(X[i:(i + seq_length)])\n",
    "    ys.append(y[i + seq_length])\n",
    "X = np.array(xs)\n",
    "y = np.array(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62d55dd",
   "metadata": {},
   "source": [
    "Slit the Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5da581f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5882839",
   "metadata": {},
   "source": [
    "Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c3e7552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define My Model\n",
    "class StockPriceRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2):\n",
    "        super(StockPriceRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36ad064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define vars\n",
    "hidden_size = 128\n",
    "num_layers = 3\n",
    "output_size = 1\n",
    "\n",
    "#Create a new model\n",
    "model = StockPriceRNN(\n",
    "    input_size=X_train.shape[2], \n",
    "    hidden_size=hidden_size, \n",
    "    output_size=output_size, \n",
    "    num_layers=num_layers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e94153",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d803ec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.0491\n",
      "Epoch [2/200], Loss: 0.1486\n",
      "Epoch [3/200], Loss: 0.0218\n",
      "Epoch [4/200], Loss: 0.0161\n",
      "Epoch [5/200], Loss: 0.0154\n",
      "Epoch [6/200], Loss: 0.0312\n",
      "Epoch [7/200], Loss: 0.0332\n",
      "Epoch [8/200], Loss: 0.0200\n",
      "Epoch [9/200], Loss: 0.0200\n",
      "Epoch [10/200], Loss: 0.0101\n",
      "Epoch [11/200], Loss: 0.0136\n",
      "Epoch [12/200], Loss: 0.0036\n",
      "Epoch [13/200], Loss: 0.0023\n",
      "Epoch [14/200], Loss: 0.0065\n",
      "Epoch [15/200], Loss: 0.0044\n",
      "Epoch [16/200], Loss: 0.0018\n",
      "Epoch [17/200], Loss: 0.0085\n",
      "Epoch [18/200], Loss: 0.0055\n",
      "Epoch [19/200], Loss: 0.0028\n",
      "Epoch [20/200], Loss: 0.0042\n",
      "Epoch [21/200], Loss: 0.0023\n",
      "Epoch [22/200], Loss: 0.0032\n",
      "Epoch [23/200], Loss: 0.0036\n",
      "Epoch [24/200], Loss: 0.0038\n",
      "Epoch [25/200], Loss: 0.0028\n",
      "Epoch [26/200], Loss: 0.0017\n",
      "Epoch [27/200], Loss: 0.0074\n",
      "Epoch [28/200], Loss: 0.0018\n",
      "Epoch [29/200], Loss: 0.0025\n",
      "Epoch [30/200], Loss: 0.0020\n",
      "Epoch [31/200], Loss: 0.0019\n",
      "Epoch [32/200], Loss: 0.0016\n",
      "Epoch [33/200], Loss: 0.0020\n",
      "Epoch [34/200], Loss: 0.0045\n",
      "Epoch [35/200], Loss: 0.0084\n",
      "Epoch [36/200], Loss: 0.0025\n",
      "Epoch [37/200], Loss: 0.0048\n",
      "Epoch [38/200], Loss: 0.0048\n",
      "Epoch [39/200], Loss: 0.0027\n",
      "Epoch [40/200], Loss: 0.0034\n",
      "Epoch [41/200], Loss: 0.0064\n",
      "Epoch [42/200], Loss: 0.0015\n",
      "Epoch [43/200], Loss: 0.0023\n",
      "Epoch [44/200], Loss: 0.0046\n",
      "Epoch [45/200], Loss: 0.0054\n",
      "Epoch [46/200], Loss: 0.0018\n",
      "Epoch [47/200], Loss: 0.0014\n",
      "Epoch [48/200], Loss: 0.0027\n",
      "Epoch [49/200], Loss: 0.0026\n",
      "Epoch [50/200], Loss: 0.0058\n",
      "Epoch [51/200], Loss: 0.0015\n",
      "Epoch [52/200], Loss: 0.0018\n",
      "Epoch [53/200], Loss: 0.0019\n",
      "Epoch [54/200], Loss: 0.0021\n",
      "Epoch [55/200], Loss: 0.0017\n",
      "Epoch [56/200], Loss: 0.0009\n",
      "Epoch [57/200], Loss: 0.0022\n",
      "Epoch [58/200], Loss: 0.0021\n",
      "Epoch [59/200], Loss: 0.0016\n",
      "Epoch [60/200], Loss: 0.0022\n",
      "Epoch [61/200], Loss: 0.0024\n",
      "Epoch [62/200], Loss: 0.0020\n",
      "Epoch [63/200], Loss: 0.0020\n",
      "Epoch [64/200], Loss: 0.0019\n",
      "Epoch [65/200], Loss: 0.0029\n",
      "Epoch [66/200], Loss: 0.0044\n",
      "Epoch [67/200], Loss: 0.0041\n",
      "Epoch [68/200], Loss: 0.0024\n",
      "Epoch [69/200], Loss: 0.0019\n",
      "Epoch [70/200], Loss: 0.0023\n",
      "Epoch [71/200], Loss: 0.0010\n",
      "Epoch [72/200], Loss: 0.0017\n",
      "Epoch [73/200], Loss: 0.0019\n",
      "Epoch [74/200], Loss: 0.0019\n",
      "Epoch [75/200], Loss: 0.0023\n",
      "Epoch [76/200], Loss: 0.0021\n",
      "Epoch [77/200], Loss: 0.0013\n",
      "Epoch [78/200], Loss: 0.0022\n",
      "Epoch [79/200], Loss: 0.0015\n",
      "Epoch [80/200], Loss: 0.0033\n",
      "Epoch [81/200], Loss: 0.0012\n",
      "Epoch [82/200], Loss: 0.0019\n",
      "Epoch [83/200], Loss: 0.0007\n",
      "Epoch [84/200], Loss: 0.0016\n",
      "Epoch [85/200], Loss: 0.0015\n",
      "Epoch [86/200], Loss: 0.0015\n",
      "Epoch [87/200], Loss: 0.0028\n",
      "Epoch [88/200], Loss: 0.0027\n",
      "Epoch [89/200], Loss: 0.0020\n",
      "Epoch [90/200], Loss: 0.0017\n",
      "Epoch [91/200], Loss: 0.0024\n",
      "Epoch [92/200], Loss: 0.0023\n",
      "Epoch [93/200], Loss: 0.0015\n",
      "Epoch [94/200], Loss: 0.0007\n",
      "Epoch [95/200], Loss: 0.0010\n",
      "Epoch [96/200], Loss: 0.0017\n",
      "Epoch [97/200], Loss: 0.0020\n",
      "Epoch [98/200], Loss: 0.0032\n",
      "Epoch [99/200], Loss: 0.0011\n",
      "Epoch [100/200], Loss: 0.0009\n",
      "Epoch [101/200], Loss: 0.0022\n",
      "Epoch [102/200], Loss: 0.0017\n",
      "Epoch [103/200], Loss: 0.0011\n",
      "Epoch [104/200], Loss: 0.0026\n",
      "Epoch [105/200], Loss: 0.0014\n",
      "Epoch [106/200], Loss: 0.0007\n",
      "Epoch [107/200], Loss: 0.0032\n",
      "Epoch [108/200], Loss: 0.0035\n",
      "Epoch [109/200], Loss: 0.0014\n",
      "Epoch [110/200], Loss: 0.0012\n",
      "Epoch [111/200], Loss: 0.0010\n",
      "Epoch [112/200], Loss: 0.0014\n",
      "Epoch [113/200], Loss: 0.0307\n",
      "Epoch [114/200], Loss: 0.0128\n",
      "Epoch [115/200], Loss: 0.0040\n",
      "Epoch [116/200], Loss: 0.0122\n",
      "Epoch [117/200], Loss: 0.0016\n",
      "Epoch [118/200], Loss: 0.0041\n",
      "Epoch [119/200], Loss: 0.0034\n",
      "Epoch [120/200], Loss: 0.0025\n",
      "Epoch [121/200], Loss: 0.0044\n",
      "Epoch [122/200], Loss: 0.0035\n",
      "Epoch [123/200], Loss: 0.0039\n",
      "Epoch [124/200], Loss: 0.0036\n",
      "Epoch [125/200], Loss: 0.0071\n",
      "Epoch [126/200], Loss: 0.0018\n",
      "Epoch [127/200], Loss: 0.0008\n",
      "Epoch [128/200], Loss: 0.0028\n",
      "Epoch [129/200], Loss: 0.0039\n",
      "Epoch [130/200], Loss: 0.0019\n",
      "Epoch [131/200], Loss: 0.0019\n",
      "Epoch [132/200], Loss: 0.0024\n",
      "Epoch [133/200], Loss: 0.0040\n",
      "Epoch [134/200], Loss: 0.0028\n",
      "Epoch [135/200], Loss: 0.0043\n",
      "Epoch [136/200], Loss: 0.0016\n",
      "Epoch [137/200], Loss: 0.0019\n",
      "Epoch [138/200], Loss: 0.0027\n",
      "Epoch [139/200], Loss: 0.0015\n",
      "Epoch [140/200], Loss: 0.0022\n",
      "Epoch [141/200], Loss: 0.0010\n",
      "Epoch [142/200], Loss: 0.0022\n",
      "Epoch [143/200], Loss: 0.0016\n",
      "Epoch [144/200], Loss: 0.0023\n",
      "Epoch [145/200], Loss: 0.0022\n",
      "Epoch [146/200], Loss: 0.0021\n",
      "Epoch [147/200], Loss: 0.0042\n",
      "Epoch [148/200], Loss: 0.0033\n",
      "Epoch [149/200], Loss: 0.0030\n",
      "Epoch [150/200], Loss: 0.0032\n",
      "Epoch [151/200], Loss: 0.0026\n",
      "Epoch [152/200], Loss: 0.0013\n",
      "Epoch [153/200], Loss: 0.0007\n",
      "Epoch [154/200], Loss: 0.0014\n",
      "Epoch [155/200], Loss: 0.0025\n",
      "Epoch [156/200], Loss: 0.0017\n",
      "Epoch [157/200], Loss: 0.0018\n",
      "Epoch [158/200], Loss: 0.0009\n",
      "Epoch [159/200], Loss: 0.0012\n",
      "Epoch [160/200], Loss: 0.0014\n",
      "Epoch [161/200], Loss: 0.0010\n",
      "Epoch [162/200], Loss: 0.0010\n",
      "Epoch [163/200], Loss: 0.0013\n",
      "Epoch [164/200], Loss: 0.0019\n",
      "Epoch [165/200], Loss: 0.0015\n",
      "Epoch [166/200], Loss: 0.0015\n",
      "Epoch [167/200], Loss: 0.0014\n",
      "Epoch [168/200], Loss: 0.0032\n",
      "Epoch [169/200], Loss: 0.0033\n",
      "Epoch [170/200], Loss: 0.0032\n",
      "Epoch [171/200], Loss: 0.0038\n",
      "Epoch [172/200], Loss: 0.0021\n",
      "Epoch [173/200], Loss: 0.0018\n",
      "Epoch [174/200], Loss: 0.0025\n",
      "Epoch [175/200], Loss: 0.0002\n",
      "Epoch [176/200], Loss: 0.0025\n",
      "Epoch [177/200], Loss: 0.0012\n",
      "Epoch [178/200], Loss: 0.0017\n",
      "Epoch [179/200], Loss: 0.0020\n",
      "Epoch [180/200], Loss: 0.0010\n",
      "Epoch [181/200], Loss: 0.0018\n",
      "Epoch [182/200], Loss: 0.0027\n",
      "Epoch [183/200], Loss: 0.0015\n",
      "Epoch [184/200], Loss: 0.0024\n",
      "Epoch [185/200], Loss: 0.0022\n",
      "Epoch [186/200], Loss: 0.0015\n",
      "Epoch [187/200], Loss: 0.0014\n",
      "Epoch [188/200], Loss: 0.0017\n",
      "Epoch [189/200], Loss: 0.0013\n",
      "Epoch [190/200], Loss: 0.0018\n",
      "Epoch [191/200], Loss: 0.0032\n",
      "Epoch [192/200], Loss: 0.0021\n",
      "Epoch [193/200], Loss: 0.0025\n",
      "Epoch [194/200], Loss: 0.0037\n",
      "Epoch [195/200], Loss: 0.0013\n",
      "Epoch [196/200], Loss: 0.0018\n",
      "Epoch [197/200], Loss: 0.0013\n",
      "Epoch [198/200], Loss: 0.0016\n",
      "Epoch [199/200], Loss: 0.0011\n",
      "Epoch [200/200], Loss: 0.0011\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 34\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs.squeeze(), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66da80b4",
   "metadata": {},
   "source": [
    "Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "799e4e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.0061\n",
      "Test Accuracy (within 5.0% tolerance): 43.64%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "    predictions = model(X_test_tensor)\n",
    "    mse = nn.MSELoss()(predictions.squeeze(), y_test_tensor)\n",
    "    print(f'Test MSE: {mse:.4f}')\n",
    "\n",
    "    # Calculate Accuracy (example - you might need to adjust based on your definition)\n",
    "    # This is a simplified example and might not be directly applicable to all regression problems.\n",
    "    # Accuracy in regression is often defined as \"how close\" the predictions are to the actual values within a certain tolerance.\n",
    "\n",
    "    tolerance = 0.05  # Define how much deviation is acceptable (e.g., 5%)\n",
    "    correct_predictions = torch.sum(torch.abs(predictions.squeeze() - y_test_tensor) <= tolerance)\n",
    "    total_predictions = y_test_tensor.size(0)\n",
    "    accuracy = (correct_predictions.float() / total_predictions) * 100\n",
    "    print(f'Test Accuracy (within {tolerance*100}% tolerance): {accuracy:.2f}%')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
